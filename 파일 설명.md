# 파일 설명



- model
  1. model.py - attention, bert model
- pretrain
  	1. namuwiki_preprocessing .py - namuwiki 덤프 데이터에서 원하는 문서의 개수만큼 문서 추출
   	2. tokenizer.py - 추출된 문서로 tokenizer 만듬(BERT Tokenizer)
   	3. dataset.py - 추출된 문서들로 MASK를 씌우고 NSP를 만듦, 즉 pretrain instance 생성
   	4. pretrain_bert.py - pretrain bert
- finetunning
  1. finetunnning.py - nsmc finetunning 시킴